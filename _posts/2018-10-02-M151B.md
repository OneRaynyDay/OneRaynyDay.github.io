---
published: false
title: Computer Architecture - Introduction
use_math: true
category: dev
layout: default
---

# Manufacturing Process of a CPU

- Silicon ingot is extracted to the purest form (any impurities will lead to a defect)
- Ingot is sliced up into wafers (thin disks)
- wafers are then etched and patterned with a layer of material above it for the circuitry of the chip
- The wafer is then sliced up into individual CPU dies
- Bond the die to the package, and ship to customers

Usually, the **yield** of a manufacturing process is the proportion of working dies per wafer (not ingot). This does not necessarily only pertain to a CPU, but also any _integrated circuit_. This is the reason why ASICS are so expensive.

# Execution Time and Throughput

**Execution time** is how long it takes to do a task, and **throughput** is how much work is done per unit time. Throughput is roughly the _bandwidth_ of a processor, and response time is specific to a task.

For example, if you have multiple cores, the execution time for a task that's single threaded or is difficult to parallelize effectively will not change, but the throughput of the multi-core chip will be higher than one that is single-core.

So how do we measure _performance_? Let us define _performance_ by:

$$
P(x) = \frac{1}{T(x)}
$$

for some task $x$, as in it is inversely proportional by the execution time. For example, if it took 10s to run a task $x$ on some machine $A$ and 15s on $B$, then one can say $A$ is 1.5x faster than $B$, because: 

$$
\frac{P^A(x)}{P^B(x)} = \frac{T^B(x)}{T^A(x)} = \frac{15}{10} = 1.5
$$

## Measuring Execution Time

- **Elapsed time**: total response time that can be measured by a clock
- **CPU time**: Time spent only on the CPU for the given task.
	- Does not account for I/O and OS context switching for other tasks to run, etc

How can we modify **CPU time**? This requires us to be familiar with a couple terminologies:

- **Clock frequency**: Cycles of a clock per second (e.x. 4.0GHz)
- **Clock period**: Duration of a single clock cycle (e.x. 0.25ns), denote as $P$.

Suppose $T$ is the CPU time, and $C$ is number of cycles required for some task:

$$
T = CP
$$

What can we do to decrease the CPU time? Well, we can either decrease the number of cycles or the time for each period. Decreasing the number of cycles for a single op could be done using vectorized instructions(doing multiple instructions at once, and _this is not necessarily the whole story_) or simply devising a better algorithm. To decrease the period, one can **overclock** a processor to run at higher GHz(and thus lower period).

So far, we have assumed that each instruction costs one cycle. We had some $C$ that we needed to lower. In reality, _there may be multiple cycles required for a single instruction_. For $N$ instructions, the $k$-th instruction which is used $N_k$ times in the procedure, which requires $I_k$ clock cycles, $C$ can be computed as :

$$
C = \sum_k^N I_k N_k
$$

So now our vectorized instruction assumption isn't necessarily true. If we can vectorize $K$ instructions, we don't necessarily get an $K$x speedup, since the vectorized instruction may cost on average more clock cycles as well.

## Amdahl's Law

Improving algorithms leads to an issue observed by Amdahl's law:

$$
T_{improved} = \frac{T_{affected}}{\text{improvement factor}} + T_{unaffected}
$$

This is simply saying that whatever you're trying to optimize, you'll never get below $T_{unaffected}$, or in other words, $T_{improved} \geq T_{unaffected}$. So the corollary or moral of the story of this law is that _if you want to optimize algorithms, make the common case fast._

# Performance Factors

- **Algorithm & compilers**: Will definitely affect instruction counts, so will affect $N_k$.
- **ISA**: Will affect $I_k$, $N_k$, and $P$.
    - For example, `CISC` vs. `RISC` ISA's will have higher and lower $P$'s respectively.

# Power Trends

$$
\text{Power} = \text{Capacitive load} * \text{voltage}^2 * \text{frequency}
$$

## The "power wall"

The power wall is a phenomenon where our current chip designs have marginal improvements on _voltage reduction and heat reduction_. How else can we reduce power? If we have denser and denser chips, it will be harder for us to cool the corresponding chips that are drawing in so much power. 

The trend between clock rate and power have been growing with each other, but lately we have switched to a multi-core processor design, which means we are keeping the clock rate the same, but just having more cores, each of which is now being optimized for lower power consumption. This is how one can keep the power consumption roughly the same but still increase performance. However, now the definition of performance is slightly different... How can we still evaluate it?

One type of benchmark uses elapsed time over multiple programs, and takes the geometric mean of all the runtimes. An example is **SPEC CPU2006**.
